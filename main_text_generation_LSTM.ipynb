{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_text_generation_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBDRHD7R75xOFwxwgWqQ18",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhijitsahoo0790/text_generation_using_LSTM/blob/master/main_text_generation_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ugM54h3E41H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "aeec24a8-2c20-400f-864f-6d704d753234"
      },
      "source": [
        "#Mount google drive to google Colab environment\n",
        "from os.path import join\n",
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb6LXyNYFJN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "For creating a new project in GitHub, it will throw error if it is executed after the project dir is created\n",
        "\"\"\"\n",
        "ROOT = \"/content/drive\"\n",
        "PROJ = \"My Drive/Colab Notebooks/text_generation_using_LSTM\" # This is a custom path.\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        "!mkdir \"{PROJECT_PATH}\"\n",
        "!git clone https://github.com/abhijitsahoo0790/text_generation_using_LSTM.git \"{PROJECT_PATH}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r28Ok3GGoJKd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "55430308-a909-4fd5-afa0-3ade618ab1bc"
      },
      "source": [
        "ROOT = \"/content/drive\"\n",
        "PROJ = \"My Drive/Colab Notebooks/text_generation_using_LSTM\" # This is a custom path.\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        "%cd \"{PROJECT_PATH}\"\n",
        "!git pull origin master"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/text_generation_using_LSTM\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 27 (delta 14), reused 24 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (27/27), done.\n",
            "From https://github.com/abhijitsahoo0790/text_generation_using_LSTM\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   6b9a15e..ff3aeba  master     -> origin/master\n",
            "Updating 6b9a15e..ff3aeba\n",
            "error: The following untracked working tree files would be overwritten by merge:\n",
            "\tdata/republic.txt\n",
            "Please move or remove them before you merge.\n",
            "Aborting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N40o2oB7GVw2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d3c2638-30a4-435d-8c5b-5411703bce32"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "import copy\n",
        "import math\n",
        "import os\n",
        "from os.path import join\n",
        "import sys\n",
        "import traceback\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)-8s %(message)s', \n",
        "                    filename='log.txt', filemode='w', level=logging.DEBUG, \n",
        "                    datefmt='%Y-%m-%d %H:%M:%S')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgoQIOBgGa6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "01da551a-2ee1-4239-ec09-20d5cad7a06f"
      },
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/Colab Notebooks/text_generation_using_LSTM/data\"\n",
        "FILE_PATH = \"wonderland.txt\"\n",
        "FULL_PATH_FILE = join(DATA_PATH, FILE_PATH)\n",
        "\n",
        "# read the text file\n",
        "f1 = open(FULL_PATH_FILE, 'r', encoding='utf-8')\n",
        "raw_text = f1.read()\n",
        "f1.close()\n",
        "\n",
        "# convert text to lower case\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)\n",
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163781\n",
            "Total Vocab:  59\n",
            "Total Patterns:  163681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4XkRBZvGsPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "830611b4-99af-462e-a470-c382ae0a8817"
      },
      "source": [
        "y.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163681, 58)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLDv2rzrLLjk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0e3c38a-4a7b-4c16-bb92-f0109845097a"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])), )\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163681/163681 [==============================] - 209s 1ms/step - loss: 2.9854\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.98543, saving model to weights-improvement-01-2.9854.hdf5\n",
            "Epoch 2/20\n",
            "163681/163681 [==============================] - 203s 1ms/step - loss: 2.7968\n",
            "\n",
            "Epoch 00002: loss improved from 2.98543 to 2.79681, saving model to weights-improvement-02-2.7968.hdf5\n",
            "Epoch 3/20\n",
            "163681/163681 [==============================] - 207s 1ms/step - loss: 2.7048\n",
            "\n",
            "Epoch 00003: loss improved from 2.79681 to 2.70477, saving model to weights-improvement-03-2.7048.hdf5\n",
            "Epoch 4/20\n",
            "163681/163681 [==============================] - 202s 1ms/step - loss: 2.6348\n",
            "\n",
            "Epoch 00004: loss improved from 2.70477 to 2.63485, saving model to weights-improvement-04-2.6348.hdf5\n",
            "Epoch 5/20\n",
            "163681/163681 [==============================] - 203s 1ms/step - loss: 2.5789\n",
            "\n",
            "Epoch 00005: loss improved from 2.63485 to 2.57891, saving model to weights-improvement-05-2.5789.hdf5\n",
            "Epoch 6/20\n",
            "163681/163681 [==============================] - 204s 1ms/step - loss: 2.5258\n",
            "\n",
            "Epoch 00006: loss improved from 2.57891 to 2.52584, saving model to weights-improvement-06-2.5258.hdf5\n",
            "Epoch 7/20\n",
            "163681/163681 [==============================] - 202s 1ms/step - loss: 2.4770\n",
            "\n",
            "Epoch 00007: loss improved from 2.52584 to 2.47701, saving model to weights-improvement-07-2.4770.hdf5\n",
            "Epoch 8/20\n",
            "163681/163681 [==============================] - 201s 1ms/step - loss: 2.4321\n",
            "\n",
            "Epoch 00008: loss improved from 2.47701 to 2.43212, saving model to weights-improvement-08-2.4321.hdf5\n",
            "Epoch 9/20\n",
            "163681/163681 [==============================] - 201s 1ms/step - loss: 2.3905\n",
            "\n",
            "Epoch 00009: loss improved from 2.43212 to 2.39048, saving model to weights-improvement-09-2.3905.hdf5\n",
            "Epoch 10/20\n",
            "163681/163681 [==============================] - 203s 1ms/step - loss: 2.3538\n",
            "\n",
            "Epoch 00010: loss improved from 2.39048 to 2.35378, saving model to weights-improvement-10-2.3538.hdf5\n",
            "Epoch 11/20\n",
            "163681/163681 [==============================] - 200s 1ms/step - loss: 2.3134\n",
            "\n",
            "Epoch 00011: loss improved from 2.35378 to 2.31342, saving model to weights-improvement-11-2.3134.hdf5\n",
            "Epoch 12/20\n",
            "163681/163681 [==============================] - 200s 1ms/step - loss: 2.2806\n",
            "\n",
            "Epoch 00012: loss improved from 2.31342 to 2.28057, saving model to weights-improvement-12-2.2806.hdf5\n",
            "Epoch 13/20\n",
            "163681/163681 [==============================] - 200s 1ms/step - loss: 2.2477\n",
            "\n",
            "Epoch 00013: loss improved from 2.28057 to 2.24770, saving model to weights-improvement-13-2.2477.hdf5\n",
            "Epoch 14/20\n",
            "163681/163681 [==============================] - 200s 1ms/step - loss: 2.2161\n",
            "\n",
            "Epoch 00014: loss improved from 2.24770 to 2.21615, saving model to weights-improvement-14-2.2161.hdf5\n",
            "Epoch 15/20\n",
            "163681/163681 [==============================] - 202s 1ms/step - loss: 2.1849\n",
            "\n",
            "Epoch 00015: loss improved from 2.21615 to 2.18488, saving model to weights-improvement-15-2.1849.hdf5\n",
            "Epoch 16/20\n",
            "163681/163681 [==============================] - 203s 1ms/step - loss: 2.1568\n",
            "\n",
            "Epoch 00016: loss improved from 2.18488 to 2.15680, saving model to weights-improvement-16-2.1568.hdf5\n",
            "Epoch 17/20\n",
            "163681/163681 [==============================] - 202s 1ms/step - loss: 2.1288\n",
            "\n",
            "Epoch 00017: loss improved from 2.15680 to 2.12878, saving model to weights-improvement-17-2.1288.hdf5\n",
            "Epoch 18/20\n",
            "163681/163681 [==============================] - 200s 1ms/step - loss: 2.1026\n",
            "\n",
            "Epoch 00018: loss improved from 2.12878 to 2.10257, saving model to weights-improvement-18-2.1026.hdf5\n",
            "Epoch 19/20\n",
            "163681/163681 [==============================] - 203s 1ms/step - loss: 2.0763\n",
            "\n",
            "Epoch 00019: loss improved from 2.10257 to 2.07632, saving model to weights-improvement-19-2.0763.hdf5\n",
            "Epoch 20/20\n",
            "163681/163681 [==============================] - 202s 1ms/step - loss: 2.0532\n",
            "\n",
            "Epoch 00020: loss improved from 2.07632 to 2.05317, saving model to weights-improvement-20-2.0532.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fab603ff240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ofqrYZCI-5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = \"weights-improvement-20-2.0532.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAnOOnMCciT8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "1b762d05-b83a-4c45-8444-ded848feb587"
      },
      "source": [
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "print(\"\\n\\n Generating Chars:\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9cdee3ae940e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pick a random seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Seed:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    }
  ]
}